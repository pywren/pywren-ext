{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import time\n",
    "import threading\n",
    "import pywren\n",
    "from importlib import reload\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "reload(pywren)\n",
    "wrenexec = pywren.local_executor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'storage_config': {'storage_backend': 's3', 'storage_prefix': 'pywren.jobs', 'backend_config': {'bucket': 'jonas-pywren-604', 'region': 'us-west-2'}}, 'func_key': 'pywren.jobs/5e98a75f-0201-476c-885a-289335d8b7ec/func.pickle', 'data_key': 'pywren.jobs/5e98a75f-0201-476c-885a-289335d8b7ec/aggdata.pickle', 'output_key': 'pywren.jobs/5e98a75f-0201-476c-885a-289335d8b7ec/00000/output.pickle', 'status_key': 'pywren.jobs/5e98a75f-0201-476c-885a-289335d8b7ec/00000/status.json', 'callset_id': '5e98a75f-0201-476c-885a-289335d8b7ec', 'job_max_runtime': 300, 'data_byte_range': (0, 11), 'call_id': '00000', 'use_cached_runtime': True, 'runtime': {'s3_bucket': 'pywren-public-us-west-2', 's3_key': 'pywren.runtimes/default_3.6.meta.json', 'runtime_storage': 's3'}, 'pywren_version': '0.3.0', 'runtime_url': 's3://pywren-public-us-west-2/e1e82c-pywren.runtimes/default_3.6.tar.gz.0038', 'host_submit_time': 1505258161.025185}\n",
      "local_task_run_dir= /tmp/task/0\n",
      "CWD IS /private/tmp/task/0 we just chdir'd to /tmp/task/0 orignal dir is /Users/jonas/projects/pywren/pywren-ext\n",
      "calling cmdstr= /tmp/condaruntime/bin/python /private/tmp/task/0/jobrunner.py /tmp/jobrunner.config.json\n"
     ]
    }
   ],
   "source": [
    "def foo(x):\n",
    "    return x + 1\n",
    "f = wrenexec.call_async(foo, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "StorageOutputNotFoundError",
     "evalue": "Output for 3fd2f8a5-5213-4f27-ad3d-a612b44ea9c9 00000 not found in storage.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/projects/pywren/pywren/pywren/storage/s3_backend.py\u001b[0m in \u001b[0;36mget_object\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3_bucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStorageNoSuchKeyError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m~/projects/pywren/pywren/pywren/storage/storage.py\u001b[0m in \u001b[0;36mget_call_output\u001b[0;34m(self, callset_id, call_id)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStorageNoSuchKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pywren/pywren/pywren/storage/s3_backend.py\u001b[0m in \u001b[0;36mget_object\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"NoSuchKey\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mStorageNoSuchKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStorageNoSuchKeyError\u001b[0m: No such key pywren.jobs/3fd2f8a5-5213-4f27-ad3d-a612b44ea9c9/00000/output.pickle found in storage.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStorageOutputNotFoundError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7ecd2ed3b286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/pywren/pywren/pywren/future.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, check_only, throw_except, storage_handler)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mcall_output_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         call_invoker_result = pickle.loads(storage_handler.get_call_output(\n\u001b[0;32m--> 160\u001b[0;31m             self.callset_id, self.call_id))\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mcall_output_time_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pywren/pywren/pywren/storage/storage.py\u001b[0m in \u001b[0;36mget_call_output\u001b[0;34m(self, callset_id, call_id)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStorageNoSuchKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStorageOutputNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallset_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStorageOutputNotFoundError\u001b[0m: Output for 3fd2f8a5-5213-4f27-ad3d-a612b44ea9c9 00000 not found in storage."
     ]
    }
   ],
   "source": [
    "f.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ITER_GRANULARITY_SEC = 0.1\n",
    "\n",
    "\n",
    "class IterFuture(object):\n",
    "    def __init__(self, method, max_iters, *args):\n",
    "        self.max_iters = max_iters\n",
    "        self.args = args\n",
    "        self.thread = threading.Thread(target=self.run_iterations, \n",
    "                                       args=[method, max_iters] + list(args))\n",
    "        self.thread.start()\n",
    "        \n",
    "        self._iteration = -1\n",
    "        \n",
    "    def run_iterations(self, method, max_iters, *args):\n",
    "        old_state = None\n",
    "        for i in range(max_iters+1):\n",
    "            old_state = method(i, old_state, *args)\n",
    "            time.sleep(ITER_GRANULARITY_SEC)\n",
    "            self._iteration = i\n",
    "        self._result = old_state\n",
    "        return old_state\n",
    "    \n",
    "    @property\n",
    "    def done(self):\n",
    "        is_done = self._iteration == (self.max_iters)\n",
    "        if is_done:\n",
    "            self.thread.join()\n",
    "        return is_done\n",
    "    \n",
    "    @property\n",
    "    def iter(self):\n",
    "        return self._iteration\n",
    "    \n",
    "        \n",
    "def itermap(method, max_iters, args):\n",
    "    return [IterFuture(method, max_iters, arg) for arg in args]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "8\n",
      "18\n",
      "28\n",
      "37\n",
      "47\n",
      "57\n",
      "67\n",
      "76\n",
      "86\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "\n",
    "def my_iterative_method(iter_k, current_state):\n",
    "    if iter_k == 0:\n",
    "        x_next = np.random.rand(N)\n",
    "    else:\n",
    "        x_next = current_state + 1.0 #  alpha * grad(x_next)\n",
    "    return x_next\n",
    "\n",
    "\n",
    "iter_future = IterFuture(my_iterative_method, 100)\n",
    "while not iter_future.done:\n",
    "    print(iter_future.iter)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "def my_iterative_method(iter_k, current_state, arg):\n",
    "    if iter_k == 0:\n",
    "        x_next = np.random.rand(N) + arg\n",
    "    else:\n",
    "        x_next = current_state + 1.0 #  alpha * grad(x_next)\n",
    "    return x_next\n",
    "\n",
    "iterfutures = itermap(my_iterative_method, 100, 10 * np.arange(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IN_NOTEBOOK = True\n",
    "\n",
    "def iterfutures_wait(futures,notebook=False):\n",
    "    \n",
    "    if notebook:\n",
    "        from tqdm import tqdm_notebook as tqdm\n",
    "    else:\n",
    "        from tqdm import tqdm\n",
    "\n",
    "    total_max_iter = np.sum([f.max_iters for f in futures])\n",
    "    last_done_iters = 0\n",
    "    with tqdm(total=total_max_iter) as pbar:\n",
    "        while True:\n",
    "            total_done_iters = np.sum([max(f.iter, 0) for f in futures])\n",
    "            delta_iters = total_done_iters - last_done_iters\n",
    "            last_done_iters = total_done_iters\n",
    "            pbar.update(delta_iters)\n",
    "            \n",
    "            if np.array([f.done for f in futures]).all():\n",
    "                break\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c65351d0e654bf484fcdcc09cbdbd0f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iterfutures = itermap(my_iterative_method, 100, 10 * np.arange(4))\n",
    "iterfutures_wait(iterfutures, IN_NOTEBOOK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how do to do this with pywren as a backing? The interesting thing is that we are repeatedly invoking\n",
    "# the same function, and just using different data\n",
    "\n",
    "N = 10\n",
    "\n",
    "def my_gradient_method(k, x_k, alpha):\n",
    "    if k == 0:\n",
    "        # init case, create initial state, do setup\n",
    "        return np.zeros(N)\n",
    "    else:\n",
    "        x_next =  x_k + alpha * grad_func(x_k)\n",
    "        return x_next\n",
    "       \n",
    "with iter_runner as IR:\n",
    "    total_iters = 100\n",
    "    alphas = [0.001, 0.01, 0.1]\n",
    "    futures = IR.itermap(my_gradient_method, total_iters, alphas)\n",
    "    \n",
    "    IR.wait(futures) # this takes a reallllllly long time. Maybe prints a prog bar? \n",
    "    \n",
    "    results = [f.result() for f in futures]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why give the checkpoints names? instead autogenerate tnems! \n",
    "\n",
    "you're going to have to pick locations for checkpoint results regardless, right? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                \n",
    "\n",
    "N = 10\n",
    "\n",
    "def my_gradient_method(k, x_k, alpha):\n",
    "    if k == 0:\n",
    "        # init case, create initial state, do setup\n",
    "        return np.zeros(N)\n",
    "    else:\n",
    "        x_next =  x_k + alpha * grad_func(x_k)\n",
    "        return x_next\n",
    "       \n",
    "with iter_runner as IR: # spins off an in-process thread\n",
    "    total_iters = 100\n",
    "    alphas = [0.001, 0.01, 0.1]\n",
    "    futures = IR.itermap(my_gradient_method, total_iters, alphas, \n",
    "                        checkpoint_names)\n",
    "    \n",
    "    IR.wait(futures) # this takes a reallllllly long time. Maybe prints a prog bar? \n",
    "    \n",
    "    results = [f.result() for f in futures]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
