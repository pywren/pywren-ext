import uuid
import boto3
import datetime


def dict_to_attrs(d):
    return [{'Name' : k, 'Value': str(v)} for k, v in d.items()]

def attr_to_dict(a):
    return {i['Name'] : i['Value'] for i in a}

    
def timestamp():
    return datetime.datetime.utcnow().isoformat()

def create(config):
    if config == {}:
        return NopLogger()

    
    return SDBDictLogger(config['domain'], 
                     config.get('always_fields', {}))

class NopLogger(object):
    def __init__(self):
        pass
    def __calL__(self, args):
        pass

class SDBLogger(object):
    # FIXME figure out the aws region from pywren? 
    def __init__(self, domain, always_fields=None, 
                 aws_region='us-west-2', logger_id= None):
        self.domain = domain
        self.aws_region = aws_region
        self.client = boto3.client('sdb', region_name=aws_region)

        # FIXMe make sure we can read/write the domain 

        # FIXME serialize cleanly
        if always_fields is None:
            self.always_fields = {}
        else:
            self.always_fields = always_fields

        if logger_id is None:
            self.logger_id = str(uuid.uuid4())
        else:
            self.logger_id = logger_id

    def __str__(self):
        return "SDBLogger(domain={},logger_id={})".format(self.domain, 
                                                          self.logger_id)

    def __getstate__(self):
        return {'domain' : self.domain,
                'always_fields' : self.always_fields,
                'logger_id' : self.logger_id,
                'aws_region' : self.aws_region}

    def __setstate__(self, x):
        self.domain = x['domain']
        self.always_fields = x['always_fields']
        self.logger_id = x['logger_id']
        self.aws_region = x['aws_region']
        
        self.client = boto3.client('sdb', self.aws_region)
        
    def __call__(self, dictval=None, **kwargs):
        timestamp_str = timestamp()
        out_attrs = self.always_fields.copy()
        if dictval is not None:
            if isinstance(dictval, dict):
                out_attrs.update(args)
            else:
                raise ValueError("dictval is not a dictionary")
        out_attrs.update(kwargs)
        out_attrs['timestamp'] = timestamp_str
        out_attrs['logger_id'] = self.logger_id

        item_id = str(uuid.uuid4())

                
        response = self.client.put_attributes(
            DomainName=self.domain, 
            ItemName=item_id, 
            Attributes=dict_to_attrs(out_attrs)
        )

    def select_query(self, expression, limit=None):
        """
        Directly execute a SDB query. Useful for getting results
        from multiple loggers. Used internally 
        for easier interface. 
        

        a nice overview of the syntax can be found here:
        https://aws.amazon.com/articles/1231

        """
        paginator = self.client.get_paginator('select')

        PaginationConfig = {}
        if limit is not None:
            PaginationConfig['MaxItems'] = limit

        response_iterator = paginator.paginate(
            SelectExpression=expression,
            PaginationConfig=PaginationConfig, 
        )
        
        def item_to_dict(x):
            d = {'id' : x['Name']}
            d.update(attr_to_dict(x['Attributes']))
            return d

        for s in response_iterator:
            if 'Items' not in s:
                return []
            for x in s['Items']:
                yield(item_to_dict(x))

    def query(self, select_fields=(), eq_fields=None,
              limit = None, match_always_fields=True, 
              match_logger_id=True, timestamp_order=True):
        """
        Get events which have been sent by this logger. 
        By default matches only logs generated by this logging
        object using the internal "id". 
        """
        if select_fields == ():
            fields_str = "*"

        select_clause_format = "select {fields} from `{domain}`"
        select_stmt = select_clause_format.format(fields = fields_str,
                                                  domain=self.domain)


        def where_term(k, v):
            return " `{}`='{}'".format(str(k), str(v))
        where_clauses = []
        if match_always_fields:
            for k, v in self.always_fields.items():
                where_clauses.append(where_term(k, v))

        if eq_fields is not None:
            for k, v in eq_fields.items():
                where_clauses.append(where_term(k, v))

        if match_logger_id:
            where_clauses.append(where_term("logger_id", self.logger_id))

        where_stmt = ""
        if len(where_clauses) > 0:
            where_stmt = " where " + " and ".join(where_clauses) 
        order_stmt = ""

        query_stmt = select_stmt + where_stmt + order_stmt
        print(query_stmt)
        
        return self.select_query(query_stmt, limit=limit)


def to_df(attr_list, parse_num=True):
    """
    Helper function to convert query output into dataframe. 
    Converts dates to times

    """
    import pandas as pd
    materialized_attr_list = list(attr_list)
    if len(materialized_attr_list) == 0:
        return None

    df = pd.DataFrame(materialized_attr_list).set_index('id')
    if parse_num:
        for k in df.columns:
            try:
                df[k] = pd.to_numeric(df[k])
            except ValueError as e:
                if 'Unable to parse string' not in e.args[0]:
                    raise
    if 'timestamp' in df:
        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)

    return df
    
